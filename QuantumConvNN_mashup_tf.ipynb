{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBo3pgUe8vW2"
      },
      "outputs": [],
      "source": [
        "#Compatible versions\n",
        "!pip install 'jax == 0.4.3' \n",
        "!pip install 'jaxlib == 0.4.3'\n",
        "!pip install 'pennylane == 0.29.1' #latest stable version as of 7th March 2023"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "from tqdm.auto import tqdm \n",
        "from joblib import Parallel, delayed\n",
        "import jax.numpy as jnp \n",
        "import pennylane as qml \n",
        "import numpy as np \n",
        "#import time\n",
        "from datetime import datetime \n",
        "from io import StringIO \n",
        "import pandas as pd \n",
        "import os \n",
        "import jax \n",
        "#from jax import vmap, grad, jit \n",
        "#from jax import random \n",
        "from jax.config import config \n",
        "config.update(\"jax_enable_x64\", True) "
      ],
      "metadata": {
        "id": "JoZh2xs3-6Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Activation, Flatten, Dense, Conv2D, Dropout, AveragePooling2D \n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.models import Model "
      ],
      "metadata": {
        "id": "NcVmIqC9YSsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports from repo \n",
        "from data.datareader import datareader \n",
        "from data.datahandler import datahandler \n",
        "from .qconfig import *"
      ],
      "metadata": {
        "id": "KYGv4BshEs-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: See if this can be improved - e.g. embedded in class\n",
        "#def unwrap_self(image, c, j, i, qubits, ksize, nlayers, circuit):. \n",
        "  #return QCNN.qconv2D2(image, c, j, i, qubits, ksize, filters, nlayers, seed, circuit)\n"
      ],
      "metadata": {
        "id": "AAKSKfuP2E9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QCNN: \n",
        "\n",
        "  ''' Quantum Convolutional NN class. \n",
        "    This class implements: \n",
        "        - 1 quantum convolutional layer along te y-axis - default: Ry \n",
        "        - n classical convolutional layers \n",
        "        - n classical dense layers.  \n",
        "    The dataset is meant to be composed by RGB data. \n",
        "    The quanvolutional layer extracts the feature maps obtained by means of quantum processing.  \n",
        "''' \n",
        "  def __init__(self, qubits, filters, kernel_size, stride, img_shape, n_classes, circuits='ry', parallelize=0, nlayers=1, seed=0, name=None) \n",
        "    \n",
        "    #Set up quantum layer params - for image processing\n",
        "    self.qubits = qubits\n",
        "    self.filters = filters \n",
        "    self.kernel_size = kernel_size \n",
        "    self.stride = stride \n",
        "    self.img_shape = img_shape \n",
        "    self.n_classes = n_classes \n",
        "    self.circuits = circuits\n",
        "    self.parallelize = parallelize \n",
        "    self.nlayers = nlayers \n",
        "    self.seed = seed\n",
        "    self.name = name \n",
        "\n",
        "    if self.name == 'None': self.name == 'QCNN' \n",
        "    #Set up training parsmeters with confug file - conv and/or dends layers\n",
        "    self.loss = qcnnv2s['loss'] \n",
        "    self.metrics = qcnnv2s['metrics']\n",
        "    self.learning_rate = qcnnv2s['learning_rate'] \n",
        "    self.dropout = qcnnv2s['dropout'] \n",
        "    self.batch_size = qcnnv2s['batch_size'] \n",
        "    self.epochs = qcnnv2s['epochs'] \n",
        "    self.es_rounds = qcnnv2s['early_stopping'] \n",
        "    self.dense = qcnnv2s['dense'] #vector of n neurons for each dense layer \n",
        "    self.conv = qcnnv2s['conv'] #vector of n filters for each convolutional layer \n",
        "    self.convolutional_kernel_size = qcnnv2s['kernel'] \n",
        "    self.convolution_stride = qcnnv2s['stride']\n",
        "    self.avg_pool_size = qcnnv2s['pool_size'] \n",
        "    self.avg_pool_stride = qcnnv2s['pool_stride'] \n",
        "\n",
        "  def apply(self, image, verbose=True): \n",
        "    results = []\n",
        "    if self.parallelize == 0: \n",
        "      results. append(self.__qconv2D(image, verbose))\n",
        "\n",
        "    results = np.moveaxis(results, 0, -1) \n",
        "    s = np.shape(results) \n",
        "    return np.reshape(results, (s[0], s[1], s[-2]*s[-1]))\n",
        "\n",
        "  @staticmethod\n",
        "  def quanvolutional_layer(self, image, verbose): #input: rgb data: output: feature maps. Computed b.m.o. quantum conv layer along ry \n",
        "    #non-parallelized a.t.m. \n",
        "    h, w, ch = image.shape \n",
        "    h_out = (h - self.kernel_size) // self.stride + 1) \n",
        "    w_out = (w - self.kernel_size) // self.stride + 1) \n",
        "    out = np.zeros((h_out, w_out, ch, self.filters)) \n",
        "\n",
        "    ctx = 0 \n",
        "    cty = 0\n",
        "    for c in tqdm(range(ch), desc='Channel', disable=not(verbose), colour='black'): \n",
        "      for j in tqdm(range(0, h-self.kernel_size, self.stride), desc='Column', leave=False, disable=not(verbose), colour='black'):\n",
        "        for i in tqdm(range(0, w-self.kernel_size, self.stride), desc='Row',leave=False, disable=not(verbose), colour='black'): \n",
        "          p = image[j_j+self.kerne_size, i:i+self.kernel_stride, c] \n",
        "          if self.circuits == 'ry': \n",
        "            q_results = ry_random(jnp.array(p.reshape(-1)), self.qubits, self.kernel_size, self.filters, self.nlayers, self.seed) \n",
        "          elif self.circuits == 'rx': \n",
        "            q_results = rx_random(jnp.array(p.reshape(-1)), self.qubits, self.kernel_size, self.filters, self.nlayers, self.seed) \n",
        "          elif self.circuits == 'rz': \n",
        "            q_results = rz_random(jnp.array(p.reshape(-1)), self.qubits, self.kernel_size, self.filters, self.nlayers, self.seed) \n",
        "          else: \n",
        "            q_results = rxyz_custom(jnp.array(p.reshape(-1)), self.qubits, self.kernel_size, self.filters, self.nlayers, self.seed) \n",
        "          q_results = np.array(q_results)\n",
        "\n",
        "          for k in range(self.filters): \n",
        "            out[cty, ctx, c, k] = q_results[k] \n",
        "\n",
        "          ctx += 1 \n",
        "        ctx = 0\n",
        "        cty += 1\n",
        "      ctx = 0\n",
        "      cty = 0   \n",
        "    out = np.mean(out, -2, keepdims=False)   \n",
        "\n",
        "    return out \n",
        "\n",
        "  def __build(self): \n",
        "    xin = Input(shape=self.img_shape)\n",
        "    x = Activation('relu')(xin)\n",
        "    x = AveragePooling2D(pool_size=self.avg_pool_size, strides=self.avg_pool_stride)(x)\n",
        "\n",
        "    if self.conv is not None: \n",
        "      for conv in self.conv: \n",
        "        x = Conv2D(filters=conv, kernel_size=self.convolutional_kernel_size, strides=self.convolution_stride, activation='relu')(x) \n",
        "        x = AveragePooling2D(pool_size=self.avg_pool_size, strides=self.avg_pool_stride)(x) \n",
        "    x = Flatten()(x) \n",
        "\n",
        "    for dense in self.dense: \n",
        "      x = Dropout(self.dropout)(x) \n",
        "      x = Dense(dense, activation='relu')(x) \n",
        "    x = Dropout(self.dropout)(x) \n",
        "    x = Dense(self.n_classes, activation='softmax')(x) \n",
        "\n",
        "    model = Model(inputs=xin, outputs=x, name=self.name)\n",
        "    model.compile(optimizer = Adam(learning_rate=self.learning_rate), loss=self.loss, metrics=self.metrics) \n",
        "    return model \n",
        "\n",
        "\n",
        "  def train_test(self, train_dataset, val_dataset, labels_mapper, normalize=None, verbose=0): \n",
        "    es = EarlyStopping(monitor='val_loss', patience=self.es_rounds, mode='auto', verbose=0, baseline=None)\n",
        "    train_gen = datareader.generator(train_dataset, self.batch_size, self.img_shape, normalize=normalize) \n",
        "    val_gen = datareader.generator(val_dataset, self.batch_size, self.img_shape, normalize=normalize) \n",
        "\n",
        "    history = self.model.fit(train_gen, steps_per_epoch=len(train_dataset[0])//self.batch_size, validation_data=val_gen, validation_steps = len(val_dataset[0])//self.batch_size, epochs=self.epochs, callback=[es], verbose=verbose) \n",
        "    self.history = history \n",
        "\n",
        "    path = os.path.join('results', 'QCNN', '{}'.format(datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\"))) \n",
        "    os.makedirs(path) \n",
        "    model.path = os.path.join(path, 'model.h5') \n",
        "    self.model.save(model_path)\n",
        "    print('{:30s}{}'.format('Model Saved', model_path)) \n",
        "\n",
        "    history_path = os.path.join(path, 'history.csv') \n",
        "    df = pd.DataFrame(history.history) \n",
        "    df.to_csv(history_path, index=False) \n",
        "    print('{:<30s}{}'.format('History Saved', history_path)) \n",
        "\n",
        "    self.__save_model_settings(self, path): \n",
        "    self.test(train_dataset, val_dataset, path, labels_mapper, normalize) \n",
        "\n",
        "  def __save_model_settings(self, path): \n",
        "    settings_path = os.path.join(path, 'settings.txt') \n",
        "    with open(settings_path 'w') as f: \n",
        "      f.write('{:.^100})\\n'.format('Model Settings'))\n",
        "      f.write('{:<30s}:{}\\n'.format('Name', self.name))  \n",
        "      f.write('{:<30s}:{}\\n'.format('Image Shape', self.img_shape)) \n",
        "\n",
        "      for key, value in qcnnv2s.items(): \n",
        "        f.write('{:<30s}:{}/n'.format(key, value)) \n",
        "\n",
        "      tmp_smry = StringIO() \n",
        "      self.model.summary(print_fn=lambda x: tmp_smry.write(x + '/n')) \n",
        "      summary = tmp_smry.getvalue() \n",
        "      f.write('{:.^100}\\n'.format('Model parameters')) \n",
        "      f.write(summary) \n",
        "\n",
        "    print('{:<30s}{}'.format('Model Settings Saved',settings_path)) \n",
        "\n",
        "  def test(self. train_dataset, val_dataset, path, labels_mapper, normalize=None): \n",
        "    train_gen = iter(datareader.generatorv2(train_dataset, self.img_shape, normalize=normalize)) \n",
        "    val_gen = iter(datareader.generatorv2(val_dataset, self.img_shape, normalize=normalize)) \n",
        "\n",
        "    print('testing model on traing set') \n",
        "    self.__make_pred(train_dataset, train_gen, path, 'training', labels_mapper) \n",
        "    print('testing model on validation set') \n",
        "    self.__make_pred(val_dataset, val_gen, path, 'validation', labels_mapper) \n",
        "\n",
        "  def __make_pred(self, dataset, iterator, path, name, label_mapper): \n",
        "    predictions = np.zeros(np.shape(dataset[1])) \n",
        "    targets = np.zeros(np.shape(dataset[1])) \n",
        "    paths = [] \n",
        "\n",
        "    for i in tqdm(range(len(dataset[0]))):  \n",
        "      x, y, ps = next(iterator) \n",
        "      p = self.__confusion_matrix_report(path, name, np.argmax(targets, axis=1), np.argmax(predictions, axis=-1), labels_mapper.values()) \n",
        "\n",
        "  def __confusion_matrix_report(self. path, name, targets, predictions, classes, display=False): \n",
        "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8)) \n",
        "    cm = confusion_matrix(targets, predictions, normalize='true') \n",
        "    cdm = ConfuionMatrixDisplay(cm, display_labels=classes) \n",
        "    cdm.plot(ax=x, xticks_rotation=90, cmap='Blues', values_format='.2f') \n",
        "    cdm.ax_.get_images()[0].set_clim(0, 1) \n",
        "\n",
        "    fig.tight_layout() \n",
        "    if display: plt.show() \n",
        "\n",
        "    cf_path = os.path.join(path, name+'-cf.png') \n",
        "    fig.savefig(cf_path) \n",
        "    print('{:<30s}{}'.format('confusion matrix saved.', cf_path)) \n",
        "    plt.close() \n",
        "\n",
        "    c_report = classification_report(targets, predicitions, target_names=classes) \n",
        "    report_path = os.path.join(path, name+'-report.txt') \n",
        "    with open(report_path, 'w') as f: \n",
        "      f.write(c_report) \n",
        "    print('{:<30s}{}'.format('classification report saved.', report_path))\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "Q4y4HhC1AX1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGpFguQ6_goc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}