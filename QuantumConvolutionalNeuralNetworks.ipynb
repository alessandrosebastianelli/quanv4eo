{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f83edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.datahandler import datahandler\n",
    "from data.datareader import datareader\n",
    "from models.QCNN import *\n",
    "from utils import test_loader\n",
    "from utils.plotter import *\n",
    "from utils.converter import convert_labels_mapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0f9e3",
   "metadata": {},
   "source": [
    "## Load processed dataset\n",
    "\n",
    "Instructions\n",
    "1. the dataset should be placed in the working directory, specifically in the **datasets** folder.\n",
    "2. the dataset should be already divided into classes, one-subfolder for earch classes. The folder/class name will be used to encode the label\n",
    "\n",
    "If this script is runned after *Quantum Convolution Processing.ipynb* the folder structure should be alredy ready.\n",
    "\n",
    "```\n",
    "QuantumCNN\n",
    "│   README.md\n",
    "│   requirements.txt    \n",
    "│\n",
    "└───circuits\n",
    "└───...\n",
    "└───datasets\n",
    "    └───EuroSAT\n",
    "        └───Highway\n",
    "                highway1.jpg\n",
    "                highway2.jpg                \n",
    "        └─── ....\n",
    "        └───Lake\n",
    "                lake1.jpg\n",
    "                lake2.jpg                \n",
    "\n",
    "```\n",
    "\n",
    "Given *the dataset_name*, that must be the same of the folder, the **datahandler** will take care of loading the paths of the feature smaps and collected them into a class dictionary. After a report of the dataset will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c33eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'EuroSAT_processed_rx'\n",
    "root = os.path.join('datasets', dataset_name)\n",
    "dhandler = datahandler(root)\n",
    "dhandler.print_report(name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8f4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set, val_set = dhandler.split(None, factor=0.2)\n",
    "dhandler.print_report(train_set, name=dataset_name+'-Train')\n",
    "dhandler.print_report(val_set,   name=dataset_name+'-Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78cc0c",
   "metadata": {},
   "source": [
    "The **unpack** function trasforms the dataset from a dictionary to an array. It assigns also the label to each image and returns a dictionary mapping the labels with the class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92497bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_mapper, x_t, y_t = dhandler.unpack(train_set)\n",
    "labels_mapper, x_v, y_v = dhandler.unpack(val_set)\n",
    "\n",
    "print('Train Set')\n",
    "print('\\nLabels')\n",
    "for key in labels_mapper: print('{:<30s}{}'.format(key,labels_mapper[key]))\n",
    "\n",
    "print('\\nDataset Size')\n",
    "print('{:<30s}{}'.format('Images', len(x_t)))\n",
    "\n",
    "print('\\nTraining Dataset samples')\n",
    "print('{:<30s}{}'.format('X Train', x_t[0]))\n",
    "print('{:<30s}{}'.format('X Train', y_t[0]))\n",
    "\n",
    "print('\\nValidation Set')\n",
    "print('\\nLabels')\n",
    "for key in labels_mapper: print('{:<30s}{}'.format(key,labels_mapper[key]))\n",
    "\n",
    "print('\\nDataset Size')\n",
    "print('{:<30s}{}'.format('Images', len(x_v)))\n",
    "\n",
    "print('\\nTraining Dataset samples')\n",
    "print('{:<30s}{}'.format('X Train', x_v[0]))\n",
    "print('{:<30s}{}'.format('X Train', y_v[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6135847",
   "metadata": {},
   "source": [
    "Test the keras-like data loader. In this specific case the *datareader.generatorv2* is tested. It contains all the rutines to load images batch by batch (1 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908798a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = dhandler.paths.keys()\n",
    "loader  = datareader.generatorv2((x_t, y_t), (31,31,8))\n",
    "test_loader.dlv2([x_t,y_t], loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aae9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader  = datareader.generatorv2((x_v, y_v), (31,31,8))\n",
    "test_loader.dlv2([x_v,y_v], loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22482fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = iter(datareader.generator((x_t, y_t), 1, (31,31,8), normalize='true'))\n",
    "for i in range(3):\n",
    "    (xi, yi) = next(gen)\n",
    "    feat_maps = xi[0]\n",
    "    plot_features_map(feat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743ff4e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = iter(datareader.generator((x_v, y_v), 1, (31,31,8), normalize='true'))\n",
    "for i in range(3):\n",
    "    (xi, yi) = next(gen)\n",
    "    feat_maps = xi[0]\n",
    "    plot_features_map(feat_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff64b68",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcd97a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "\n",
    "qcnn = QCNNv1(img_shape = (31,31,8), n_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61f931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qcnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0688060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qcnn.train_test([x_t, y_t], [x_v, y_v], convert_labels_mapper(labels_mapper), normalize = None, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea1569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "from utils import plotter\n",
    "reload(plotter)\n",
    "\n",
    "plotter.plot_training('QCNNv1', display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f0cf1-27dc-4875-8cce-e4b58f409eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
