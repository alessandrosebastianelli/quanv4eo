{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251adf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datahandler import datahandler\n",
    "from data.datareader import datareader\n",
    "from utils import test_loader\n",
    "from utils.plotter import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef61117",
   "metadata": {},
   "source": [
    "## Load processed dataset\n",
    "\n",
    "Instructions\n",
    "1. the dataset should be placed in the working directory, specifically in the **datasets** folder.\n",
    "2. the dataset should be already divided into classes, one-subfolder for earch classes. The folder/class name will be used to encode the label\n",
    "\n",
    "If this script is runned after *Quantum Convolution Processing.ipynb* the folder structure should be alredy ready.\n",
    "\n",
    "```\n",
    "QuantumCNN\n",
    "│   README.md\n",
    "│   requirements.txt    \n",
    "│\n",
    "└───circuits\n",
    "└───...\n",
    "└───datasets\n",
    "    └───EuroSAT\n",
    "        └───Highway\n",
    "                highway1.jpg\n",
    "                highway2.jpg                \n",
    "        └─── ....\n",
    "        └───Lake\n",
    "                lake1.jpg\n",
    "                lake2.jpg                \n",
    "\n",
    "```\n",
    "\n",
    "Given *the dataset_name*, that must be the same of the folder, the **datahandler** will take care of loading the paths of the feature smaps and collected them into a class dictionary. After a report of the dataset will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1046fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EuroSAT_processed'\n",
    "root = os.path.join('datasets', dataset_name)\n",
    "dhandler = datahandler(root)\n",
    "dhandler.print_report(name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc5700",
   "metadata": {},
   "source": [
    "The **unpack** function trasforms the dataset from a dictionary to an array. It assigns also the label to each image and returns a dictionary mapping the labels with the class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b09b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mapper, x, y = dhandler.unpack(dhandler.paths)\n",
    "\n",
    "print('Labels')\n",
    "for key in labels_mapper: print('{:<30s}{}'.format(key,labels_mapper[key]))\n",
    "\n",
    "print('\\nDataset Size')\n",
    "print('{:<30s}{}'.format('Images', len(x)))\n",
    "\n",
    "print('\\nTraining Dataset samples')\n",
    "print('{:<30s}{}'.format('X Train', x[0]))\n",
    "print('{:<30s}{}'.format('X Train', y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac360c2",
   "metadata": {},
   "source": [
    "Test the keras-like data loader. In this specific case the *datareader.generatorv2* is tested. It contains all the rutines to load images batch by batch (1 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dhandler.paths.keys()\n",
    "loader  = datareader.generatorv2((x, y), (64,64,3))\n",
    "test_loader.dlv2([x,y], loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(datareader.generator((x, y), 1, (64,64,16), normalize=None))\n",
    "for i in range(15):\n",
    "    (xi, yi) = next(gen)\n",
    "    feat_maps = xi[0]\n",
    "    plot_features_map(feat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi.min(), xi.max(), type(feat_maps[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd20c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5e980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
